# Fichier: model_development.py
import os
import pickle
import pandas as pd
from sklearn.compose import make_column_transformer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler, StandardScaler

# DÃ©finition des chemins pour Airflow
WORKING_DIR = "/opt/airflow/working_data"
MODEL_DIR = "/opt/airflow/model"

# CrÃ©ation des rÃ©pertoires s'ils n'existent pas
os.makedirs(WORKING_DIR, exist_ok=True)
os.makedirs(MODEL_DIR, exist_ok=True)

def load_data() -> str:
    """
    Charger le fichier CSV advertising.csv et sauvegarder le dataframe brut.

    Returns:
        str: Chemin vers le fichier pickle sauvegardÃ©
    """
    csv_path = os.path.join(
        os.path.dirname(os.path.dirname(os.path.dirname(__file__))),  # Remonter de src/dags Ã  la racine
        "advertising.csv",
    )

    # Charger les donnÃ©es
    df = pd.read_csv(csv_path)

    # Sauvegarder en pickle
    out_path = os.path.join(WORKING_DIR, "raw.pkl")
    with open(out_path, "wb") as f:
        pickle.dump(df, f)

    print(f"DonnÃ©es brutes chargÃ©es et sauvegardÃ©es: {df.shape}")
    return out_path

def data_preprocessing(file_path: str) -> str:
    """
    PrÃ©traiter les donnÃ©es: nettoyage, splitting, scaling

    Args:
        file_path: Chemin vers le fichier pickle des donnÃ©es brutes

    Returns:
        str: Chemin vers le fichier pickle prÃ©traitÃ©
    """
    # Charger les donnÃ©es brutes
    with open(file_path, "rb") as f:
        df = pickle.load(f)

    # PrÃ©paration des features et target
    X = df.drop(
        ["Timestamp", "Clicked on Ad", "Ad Topic Line", "Country", "City"],
        axis=1,
    )
    y = df["Clicked on Ad"]

    print(f"Features shape: {X.shape}, Target shape: {y.shape}")

    # Split train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42
    )

    print(f"Train set: {X_train.shape}, Test set: {X_test.shape}")

    # DÃ©finition des colonnes numÃ©riques pour le scaling
    num_columns = [
        "Daily Time Spent on Site",
        "Age",
        "Area Income",
        "Daily Internet Usage",
        "Male",
    ]

    # CrÃ©ation du ColumnTransformer pour le preprocessing
    ct = make_column_transformer(
        (MinMaxScaler(), num_columns),
        (StandardScaler(), num_columns),
        remainder="passthrough",
    )

    # Appliquer le preprocessing
    X_train_tr = ct.fit_transform(X_train)
    X_test_tr = ct.transform(X_test)

    print(f"X_train transformÃ© shape: {X_train_tr.shape}")
    print(f"X_test transformÃ© shape: {X_test_tr.shape}")

    # Sauvegarder les donnÃ©es prÃ©traitÃ©es
    out_path = os.path.join(WORKING_DIR, "preprocessed.pkl")
    with open(out_path, "wb") as f:
        pickle.dump((X_train_tr, X_test_tr, y_train.values, y_test.values), f)

    return out_path

def separate_data_outputs(file_path: str) -> str:
    """
    Fonction de passage pour maintenir la structure du DAG

    Args:
        file_path: Chemin vers le fichier pickle prÃ©traitÃ©

    Returns:
        str: MÃªme chemin (passthrough)
    """
    return file_path

def build_model(file_path: str, filename: str) -> str:
    """
    EntraÃ®ner le modÃ¨le de rÃ©gression logistique et le sauvegarder

    Args:
        file_path: Chemin vers le fichier pickle prÃ©traitÃ©
        filename: Nom du fichier modÃ¨le Ã  sauvegarder

    Returns:
        str: Chemin vers le modÃ¨le sauvegardÃ©
    """
    # Charger les donnÃ©es prÃ©traitÃ©es
    with open(file_path, "rb") as f:
        X_train, X_test, y_train, y_test = pickle.load(f)

    print(f"EntraÃ®nement du modÃ¨le avec X_train shape: {X_train.shape}")

    # CrÃ©ation et entraÃ®nement du modÃ¨le
    model = LogisticRegression(random_state=42, max_iter=1000)
    model.fit(X_train, y_train)

    # Sauvegarder le modÃ¨le
    model_path = os.path.join(MODEL_DIR, filename)
    with open(model_path, "wb") as f:
        pickle.dump(model, f)

    print(f"ModÃ¨le entraÃ®nÃ© et sauvegardÃ©: {model_path}")
    return model_path

def load_model(file_path: str, filename: str) -> int:
    """
    Charger le modÃ¨le et faire des prÃ©dictions

    Args:
        file_path: Chemin vers le fichier pickle prÃ©traitÃ©
        filename: Nom du fichier modÃ¨le

    Returns:
        int: PremiÃ¨re prÃ©diction du modÃ¨le
    """
    # Charger les donnÃ©es prÃ©traitÃ©es
    with open(file_path, "rb") as f:
        X_train, X_test, y_train, y_test = pickle.load(f)

    # Charger le modÃ¨le entraÃ®nÃ©
    model_path = os.path.join(MODEL_DIR, filename)
    with open(model_path, "rb") as f:
        model = pickle.load(f)

    # Ã‰valuer le modÃ¨le
    score = model.score(X_test, y_test)
    print(f"Score du modÃ¨le sur les donnÃ©es de test: {score:.4f}")

    # Faire une prÃ©diction
    pred = model.predict(X_test)
    print(f"Exemple de prÃ©diction: {pred[0]}")

    # Retourner la premiÃ¨re prÃ©diction comme entier
    return int(pred[0])

def print_model_summary(file_path: str, filename: str) -> str:
    """
    Afficher un rÃ©sumÃ© dÃ©taillÃ© du modÃ¨le

    Args:
        file_path: Chemin vers le fichier pickle prÃ©traitÃ©
        filename: Nom du fichier modÃ¨le

    Returns:
        str: RÃ©sumÃ© du modÃ¨le
    """
    # Charger les donnÃ©es et le modÃ¨le
    with open(file_path, "rb") as f:
        X_train, X_test, y_train, y_test = pickle.load(f)

    model_path = os.path.join(MODEL_DIR, filename)
    with open(model_path, "rb") as f:
        model = pickle.load(f)

    # Calculer les mÃ©triques
    train_score = model.score(X_train, y_train)
    test_score = model.score(X_test, y_test)

    # CrÃ©er le rÃ©sumÃ©
    summary = f"""
    === RÃ©sumÃ© du modÃ¨le de RÃ©gression Logistique ===

    ğŸ“Š Performance:
    - Score Train: {train_score:.4f}
    - Score Test:  {test_score:.4f}
    - DiffÃ©rence:  {abs(train_score - test_score):.4f}

    ğŸ“ˆ DonnÃ©es:
    - Train samples: {len(y_train)}
    - Test samples:  {len(y_test)}
    - Ratio Test:    {len(y_test)/(len(y_train)+len(y_test)):.2%}

    ğŸ¯ Classes:
    - Classe 0 (Pas de click): {len(y_test)-sum(y_test)} samples
    - Classe 1 (Click):       {sum(y_test)} samples

    ğŸ“‹ Features: 5 features numÃ©riques aprÃ¨s preprocessing
    """

    print(summary)

    # Sauvegarder le rÃ©sumÃ©
    summary_path = os.path.join(MODEL_DIR, "model_summary.txt")
    with open(summary_path, "w") as f:
        f.write(summary)

    return summary_path