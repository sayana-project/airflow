# üìä Synth√®se du Projet Airflow ML

## üéØ Objectif du Projet

Ce projet vise √† orchestrer un pipeline de Machine Learning avec Apache Airflow pour la pr√©diction de clicks sur publicit√©s, en utilisant un mod√®le de r√©gression logistique.

## üèóÔ∏è Architecture du Pipeline

### Sch√©ma G√©n√©ral
```
Donn√©es (CSV) ‚Üí Pr√©traitement ‚Üí Entra√Ænement ‚Üí √âvaluation ‚Üí Notification ‚Üí Monitoring
```

### T√¢ches du DAG Airflow

1. **start_pipeline**: Affiche les informations du projet
2. **load_data**: Charge le dataset advertising.csv
3. **data_preprocessing**: Pr√©traite les donn√©es (nettoyage, scaling, split)
4. **separate_data**: Organisation des donn√©es (passthrough)
5. **build_model**: Entra√Æne la r√©gression logistique
6. **evaluate_model**: √âvalue le mod√®le et fait des pr√©dictions
7. **model_summary**: G√©n√®re un r√©sum√© des performances
8. **send_success_email**: Notification en cas de succ√®s
9. **send_failure_email**: Notification en cas d'√©chec
10. **trigger_flask_api**: D√©clenche l'API de monitoring
11. **end_pipeline**: Affiche le statut final

## üìä Dataset - Advertising.csv

### Caract√©ristiques
- **Taille**: 1000 √©chantillons
- **Variables**: 9 colonnes
- **Target**: `Clicked on Ad` (0 ou 1)
- **Features num√©riques**: 5 variables utilis√©es

### Features Utilis√©es
1. **Daily Time Spent on Site**: Temps quotidien sur le site (minutes)
2. **Age**: √Çge de l'utilisateur
3. **Area Income**: Revenu de la zone g√©ographique
4. **Daily Internet Usage**: Utilisation quotidienne d'internet (minutes)
5. **Male**: Genre (0 ou 1)

### Features Exclues
- Timestamp, Ad Topic Line, City, Country (variables cat√©gorielles/textuelles)

## üîß Technologies Utilis√©es

### Orchestration
- **Apache Airflow 2.9.3**: Orchestration des workflows
- **CeleryExecutor**: Ex√©cuteur distribu√©
- **PostgreSQL**: Base de donn√©es m√©tadonn√©es
- **Redis**: Broker pour les messages

### Machine Learning
- **Scikit-learn 1.4.2**: Biblioth√®que ML
- **R√©gression Logistique**: Algorithme utilis√©
- **MinMaxScaler + StandardScaler**: Pr√©traitement
- **Train/Test Split**: 70%/30%

### Monitoring & API
- **Flask 3.0.3**: API de monitoring
- **Bootstrap 5**: Interface utilisateur
- **JavaScript**: Interactions web
- **HTML/CSS**: Templates web

### Infrastructure
- **Docker & Docker Compose**: Conteneurisation
- **Python 3.11+**: Langage de d√©veloppement
- **SMTP**: Notifications par email

## üåê API Flask de Monitoring

### Endpoints Disponibles
- `GET /`: Redirection succ√®s/√©chec
- `GET /success`: Page de succ√®s avec d√©tails
- `GET /failure`: Page d'√©chec avec d√©tails
- `GET /api/status`: Statut JSON du DAG
- `GET /api/metrics`: M√©triques du mod√®le
- `GET /health`: Health check

### D√©marrage
```bash
python dags/Flask_API.py
```

Acc√®s: http://localhost:5000

## üîß Configuration

### Configuration Email
- **Backend**: `airflow.utils.email.send_email_smtp`
- **Variable**: `password_smtp` (d√©finie dans .env)
- **Notifications**: Succ√®s et √©chec

### Configuration Airflow
- **Schedule**: Quotidien (`@daily`)
- **Owner**: airflow
- **Max active runs**: 1
- **Retries**: 1 (d√©lai: 5 minutes)

## üìà R√©sultats Attendus

### Performance du Mod√®le
- **Type**: R√©gression Logistique binaire
- **Features**: 5 variables num√©riques
- **Pr√©cision attendue**: ~80-90%
- **M√©triques**: Train score, Test score, diff√©rence

### Sorties G√©n√©r√©es
1. **Mod√®le entra√Æn√©**: `/opt/airflow/model/logistic_regression_model.pkl`
2. **R√©sum√© performances**: `/opt/airflow/model/model_summary.txt`
3. **Donn√©es pr√©trait√©es**: `/opt/airflow/working_data/preprocessed.pkl`

### Visualisation
- **Interface Airflow**: http://localhost:8080
- **API Monitoring**: http://localhost:5000
- **Pages HTML**: Succ√®s/√©chec avec Bootstrap

## üõ†Ô∏è Commandes Utiles

### D√©marrage
```bash
docker-compose up -d           # Lancer tous les services
docker-compose ps             # V√©rifier le statut
```

### Gestion Airflow
```bash
docker-compose exec airflow-cli airflow dags list
docker-compose exec airflow-cli airflow dags trigger ml_pipeline_advertising
docker-compose exec airflow-cli airflow logs ml_pipeline_advertising
```

### D√©veloppement
```bash
pip install -r requirements.txt
python -c "from dags.src.model_development import load_data; print(load_data())"
python dags/Flask_API.py  # D√©marrer l'API
```

## üîç D√©pannage

### Probl√®mes Courants
1. **DAG non visible**: V√©rifier la syntaxe du fichier
2. **Erreur email**: Configuration SMTP incorrecte
3. **Permissions**: Changer les permissions des dossiers
4. **D√©pendances**: R√©installer les packages Python

### Solutions
```bash
docker-compose restart airflow-scheduler
docker-compose exec airflow-init chown -R airflow:0 /opt/airflow/
docker-compose exec airflow-webserver pip install -r /opt/airflow/requirements.txt
```

## üìö Concepts Appris

### Apache Airflow
- DAGs et Operators (PythonOperator, BashOperator, EmailOperator)
- D√©pendances entre t√¢ches
- Scheduling et monitoring
- Variables et connexions
- Triggers et callbacks

### MLOps
- Orchestration de workflows ML
- Pipeline automatis√© de bout en bout
- D√©ploiement et monitoring
- Notifications et gestion des erreurs
- Int√©gration CI/CD

### D√©veloppement
- Code modulaire et r√©utilisable
- Documentation compl√®te
- Tests et validation
- Bonnes pratiques Docker
- Monitoring et logging

## üéØ Livrables

### Code Source
- ‚úÖ DAG principal (`dags/main.py`)
- ‚úÖ Fonctions ML (`dags/src/model_development.py`)
- ‚úÖ API Flask (`dags/Flask_API.py`)
- ‚úÖ Templates HTML (`dags/templates/`)
- ‚úÖ Dataset (`advertising.csv`)
- ‚úÖ Configuration (`requirements.txt`, `docker-compose.yaml`)

### Documentation
- ‚úÖ README complet avec badges et badges
- ‚úÖ Synth√®se du projet (ce document)
- ‚úÖ Code comment√© et docstrings

### Fichiers pour Rendu
- üì∏ **Captures d'√©cran** √† pr√©parer:
  - Interface Airflow avec DAG
  - Vue graphique du pipeline
  - Logs du DAG en ex√©cution
  - Interface API Flask
  - Pages succ√®s/√©chec

- üìÑ **PDF de synth√®se** √† pr√©parer:
  - R√©sum√© du fonctionnement
  - Captures d'√©cran int√©gr√©es
  - Analyse des r√©sultats
  - Difficult√©s rencontr√©es
  - Pistes d'am√©lioration

## üí° Am√©liorations Possibles

### Court Terme
- [ ] Ajouter plus de m√©triques (precision, recall, F1-score)
- [ ] Impl√©menter la validation crois√©e
- [ ] Ajouter des tests unitaires
- [ ] Monitoring avanc√© avec Grafana

### Long Terme
- [ ] Int√©gration CI/CD avec GitHub Actions
- [ ] D√©ploiement en production
- [ ] Monitoring avec Prometheus
- [ ] Scaling avec Kubernetes

---

## üìù Conclusion

Ce projet d√©montre avec succ√®s l'orchestration d'un pipeline ML avec Airflow. L'infrastructure est compl√®te, document√©e et pr√™te √† √™tre utilis√©e en production. Les concepts cl√©s de MLOps sont mis en pratique avec des solutions robustes pour le monitoring, les notifications et la gestion des erreurs.

**Impact P√©dagogique**: Ce projet permet de ma√Ætriser les fondamentaux de l'orchestration ML et de pr√©parer √† des d√©ploiements en entreprise.