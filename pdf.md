# Mini Projet MLOps - Pipeline ML avec Airflow

## Qu'est-ce que j'ai fait ?

J'ai cr√©√© un pipeline de Machine Learning avec Apache Airflow. C'est un programme qui automatise tout le travail ML.

## Mon setup technique

- Docker + Docker Compose
- Airflow 3.1.0
- Flask API pour le monitoring
- Gmail pour les notifications
- Mod√®le de r√©gression logistique

## Comment fonctionne Airflow ?

Airflow, c'est comme un chef de projet d'orchestre :

1. **DAG** : C'est le plan du projet (mon fichier main.py)
2. **T√¢ches** : Chaque petit programme √† faire
3. **D√©pendances** : L'ordre dans lequel les t√¢ches doivent s'ex√©cuter

Mon DAG s'appelle `ml_pipeline_advertising` et il s'ex√©cute tous les jours.

## Mon pipeline √©tape par √©tape

### 1. Chargement des donn√©es
- Je lis le fichier `advertising.csv`
- Je sauvegarde en format pickle (plus rapide)

### 2. Pr√©traitement
- Je nettoie les donn√©es
- Je s√©pare features et target
- Je fais train/test split (70%/30%)
- Je scale avec MinMaxScaler

### 3. Entra√Ænement du mod√®le
- Je cr√©e une r√©gression logistique
- Je l'entra√Æne avec les donn√©es
- Je sauvegarde le mod√®le entra√Æn√©

### 4. √âvaluation
- Je teste le mod√®le sur les donn√©es de test
- Je calcule le score de pr√©cision
- Je g√©n√®re un r√©sum√© d√©taill√©

### 5. Notifications
- Si tout marche bien : email de succ√®s
- Si la fonction √©choue : email d'√©chec
- Je d√©clenche l'API Flask pour le monitoring

## Screenshots de mon travail

### L'interface Airflow - Mon DAG
![Mon DAG principal](images/screenshot_airflow_dag.png)

### Le dashboard Airflow
![Dashboard Airflow](images/dashbaord_airflow.png)

### Configuration SMTP s√©curis√©e
![Setup email](images/admin_securit√©_smtp.png)

### R√©sultats du pipeline
![Test DAG succ√®s et √©chec](images/result_test_dag_fail_and_sucess.png)

### Email re√ßu apr√®s l'ex√©cution
![Email de notification](images/screenshot_email.png)

### Graph complet du DAG r√©ussi
![Pipeline complet r√©ussi](images/dag_graph_resultat_sucess_complet.png)

## Mes r√©sultats

### ‚úÖ Ce qui marche :
- Le pipeline s'ex√©cute compl√®tement
- Le mod√®le atteint ~85-90% de pr√©cision
- Les emails partent correctement
- Le mod√®le est bien sauvegard√©
- L'API Flask fonctionne pour le monitoring

### üìä Performances :
- **Dataset** : 1000 √©chantillons publicitaires
- **Mod√®le** : R√©gression logistique
- **Features** : 5 variables num√©riques
- **Pr√©cision** : Environ 87%

## Ce que j'ai appris

### Technique :
- Comment orchestrer un workflow ML
- Les d√©pendances entre t√¢ches
- La configuration Airflow
- Les templates Jinja
- Le docker-compose pour Airflow

### MLOps :
- Industrialiser un mod√®le ML
- Automatiser les pipelines
- Monitorer les ex√©cutions
- G√©rer les erreurs
- Envoyer des notifications

## Probl√®mes rencontr√©s et solutions

### Probl√®me 1 : Dataset pas trouv√©
**Solution** : Copier `advertising.csv` dans le bon dossier

### Probl√®me 2 : Erreur XCom dans Airflow
**Solution** : Simplifier la configuration du TriggerDagRunOperator

### Probl√®me 3 : Configuration SMTP
**Solution** : Utiliser le fichier `.env` pour s√©curiser les mots de passe

## Conclusion

Ce projet m'a appris √† passer d'un mod√®le ML qui fonctionne localement √† un pipeline complet en production. J'ai automatis√© tout le processus et maintenant mon mod√®le s'entra√Æne tout seul tous les jours sans que j'aie √† toucher √† rien !
